{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentencepiece as spm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(177) LOG(INFO) Running command: --input=merged_text.txt --model_prefix=m --vocab_size=100000\n",
      "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: merged_text.txt\n",
      "  input_format: \n",
      "  model_prefix: m\n",
      "  model_type: UNIGRAM\n",
      "  vocab_size: 100000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.9995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  pretokenization_delimiter: \n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "  enable_differential_privacy: 0\n",
      "  differential_privacy_noise_level: 0\n",
      "  differential_privacy_clipping_threshold: 0\n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(351) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(183) LOG(INFO) Loading corpus: merged_text.txt\n",
      "trainer_interface.cc(378) LOG(WARNING) Found too long line (4486 > 4192).\n",
      "trainer_interface.cc(380) LOG(WARNING) Too long lines are skipped in the training.\n",
      "trainer_interface.cc(381) LOG(WARNING) The maximum length can be changed with --max_sentence_length=<size> flag.\n",
      "trainer_interface.cc(389) LOG(INFO) Reserved chars are found. Skipped: ይህን ያውቁ ኖሯል የአለማችን የመጀመሪያዋ መኪና የተሰራችው እንደ ፈረንጆቹ አቆጣጠር በ1885 ሲሆን ሞዴሏም የተሰራው በKarl Benz’s ሲሆን ዲዛይኑ የተወሰደው ደሞ ከፈረስ መሆኑ እኔን ትንሽ አስገርሞኛል!፦ መኪናዋን ሳያት ደሞ አስቆኛልም ምንጭ[Google] New channel Join ▄ ▅ ▆\n",
      "trainer_interface.cc(389) LOG(INFO) Reserved chars are found. Skipped: ይገርማል አንድ አባት የልጁን ህክምና ወጪ ለመሸፈን ኩላሊቱን ሸጦ አድኗት ልጁ ግን ለፍቅረኛዋ ብላ እራሷን አጠፋች ምንጭ[Instagram] ▄ ▅ ▆ ▇\n",
      "trainer_interface.cc(389) LOG(INFO) Reserved chars are found. Skipped: ይገርማል JULIO MACIAS የተባለ ሜክሲኮ ውስጥ የሞኖር የ17 አመት ልጅ ፍቅረኛው በፍቅር አንገቱን ስትነክሰው ሞተ።አስከሬኑ ሲመረመርም ፍቅረኛው ስትነክሰው ወደ አንጎሉ ሚሄደው ደም በመቋረጡ እንደሞተ ተረጋግጧል ምንጭ[Instagram] ▄ ▅ ▆ ▇\n",
      "trainer_interface.cc(389) LOG(INFO) Reserved chars are found. Skipped: ይገርማል ብራዚል ውስጥ ያሉ የግንባታ ሰራተኞች የእግረኛ መንገድ እየሰሩ የሚሰሩበት ቦታ ላይ የቆመ መኪና ነበር። መኪማው እንዲነሳ የመኪናውን ባለቤት ቢፈልጉትም ሊያገኙት ስላልቻሉ ፎቶው ላይ እንደምታዩት አርገውታል ምንጭ[Instagram] ▄ ▅ ▆ ▇\n",
      "trainer_interface.cc(389) LOG(INFO) Reserved chars are found. Skipped: \"ይህን ያውቁ ኖሯል የመጀመሪያው የአሜሪካ ባንክ ዝርፊያ 162,821 የአሜሪካ ዶላር ሲሆን ዘራፊው የዘረፈውን ገንዘብ መልሶ እዛው ባንክ በማስቀመጡ ሊያዝ ችሏል ምንጭ[Instagram] ▄ ▅ ▆ ▇\"\n",
      "trainer_interface.cc(389) LOG(INFO) Reserved chars are found. Skipped: ይህን ያውቁ ኖሯል አንድ ሰውዬ ሙዚየም ውስጥ መነፅሩ ወድቆበት ረስቶ ሲሄድ ሙዚየም ውስጥ የሚገቡ ሰዎች መነፅሩ የጥበብ ስራ መስሏቸው ፎቶ ሲያነሱት ነበር ምንጭ[Instagram] ▄ ▅ ▆ ▇\n",
      "trainer_interface.cc(389) LOG(INFO) Reserved chars are found. Skipped: ይህን ያውቁ ኖሯል በደቡብ ሱዳን 4 ኣይን ያለው አዲስ እንሰሳ ተገኝቷል ምንጭ[Instagram] ▄ ▅ ▆ ▇\n",
      "trainer_interface.cc(389) LOG(INFO) Reserved chars are found. Skipped: ይህን ያውቁ ኖሯል ሴቷ አንበሳ ከወንዱ አንበሳ ጋር ወሲብ ማረግ ፈልጋ ወንዱ እምቢ ካለ ሰቷ የብልቱን ፍሬዎች ትነክሰዋለች ምንጭ[Instagram] ▄ ▅ ▆ ▇\n",
      "trainer_interface.cc(389) LOG(INFO) Reserved chars are found. Skipped: ይገርናል በለንደን የአንዲት ሴት ሶፋ ላይ ቁጭ ብላ tv እያየች ሞተች። ከዚያም ከሞተች 4 አመታት ቡሃላ TVው ክፍት እንደሆነ እሷም ሶፋ ላይ እንደተቀመጠች አ���ሟ ተገኘ ምንጭ[Instagram] ▄ ▅ ▆ ▇\n",
      "trainer_interface.cc(389) LOG(INFO) Reserved chars are found. Skipped: ይገርማል አንዱ ተማሪ አምቡላንስ ውስጥ የልብ ምቱ ቆሞ በቃ ሞቷል ከተባለ ቡሃላ ሆስፒታል ውስጥ በድንገት ነቃ። ከዛ ሃኪሞች ከሞት ቡሃላ ህይወት ስሜቱ እንዴት ነው ብለው ሲጠይቁት ሚገርም ነገር ተናገረ። ሞተ በተባለ ሰኣት መንፈሱ ከሞተው ሰውነቱ አጠገብ ተቀምጦ የሆነውን ነገር እንዳየ ተናግሮ አምቡላንስ ውስጥ የተፈጠረውን ነገር በሙሉ አንድም ሳያስቀር ነገራቸው እናም ትክክል ነበር። ምንጭ[Google] ▄ ▅ ▆ ▇\n",
      "trainer_interface.cc(389) LOG(INFO) Reserved chars are found. Skipped: ይህን ያውቁ ኖሯል በህልማቹ ምታዩአቸው ሰዎች በሙሉ በእውነተኛ ህይወታቹ ያያቹሃቸው ሰ���ች ናቸው ምክንያቱም ጭንቅላታችን አዲስ ፊት መፍጠር አይችልም ምንጭ[Instagram] ▄ ▅ ▆ ▇\n",
      "trainer_interface.cc(407) LOG(INFO) Loaded all 518282 sentences\n",
      "trainer_interface.cc(414) LOG(INFO) Skipped 2312 too long sentences.\n",
      "trainer_interface.cc(423) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(423) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(423) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(428) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(537) LOG(INFO) all chars count=73348508\n",
      "trainer_interface.cc(548) LOG(INFO) Done: 99.9511% characters are covered.\n",
      "trainer_interface.cc(558) LOG(INFO) Alphabet size=330\n",
      "trainer_interface.cc(559) LOG(INFO) Final character coverage=0.999511\n",
      "trainer_interface.cc(591) LOG(INFO) Done! preprocessed 517901 sentences.\n",
      "unigram_model_trainer.cc(222) LOG(INFO) Making suffix array...\n",
      "unigram_model_trainer.cc(226) LOG(INFO) Extracting frequent sub strings... node_num=37562228\n",
      "unigram_model_trainer.cc(274) LOG(INFO) Initialized 807415 seed sentencepieces\n",
      "trainer_interface.cc(597) LOG(INFO) Tokenizing input sentences with whitespace: 517901\n",
      "trainer_interface.cc(608) LOG(INFO) Done! 726983\n",
      "unigram_model_trainer.cc(564) LOG(INFO) Using 726983 sentences for EM training\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=365528 obj=12.378 num_tokens=1423781 num_tokens/piece=3.89514\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=312764 obj=10.7276 num_tokens=1425266 num_tokens/piece=4.557\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=234531 obj=10.7007 num_tokens=1494721 num_tokens/piece=6.37323\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=234353 obj=10.6861 num_tokens=1495979 num_tokens/piece=6.38344\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=175761 obj=10.7476 num_tokens=1595342 num_tokens/piece=9.07677\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=175754 obj=10.7313 num_tokens=1595403 num_tokens/piece=9.07748\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=131813 obj=10.8235 num_tokens=1700281 num_tokens/piece=12.8992\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=131811 obj=10.8033 num_tokens=1700289 num_tokens/piece=12.8994\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=110000 obj=10.8752 num_tokens=1764422 num_tokens/piece=16.0402\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=110000 obj=10.861 num_tokens=1764425 num_tokens/piece=16.0402\n",
      "trainer_interface.cc(686) LOG(INFO) Saving model: m.model\n",
      "trainer_interface.cc(698) LOG(INFO) Saving vocabs: m.vocab\n"
     ]
    }
   ],
   "source": [
    "import sentencepiece as spm\n",
    "\n",
    "# train sentencepiece model from `merged_text.txt` and makes `m.model` and `m.vocab`\n",
    "# `m.vocab` is just a reference. not used in the segmentation.\n",
    "spm.SentencePieceTrainer.train('--input=merged_text.txt --model_prefix=m --vocab_size=100000')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁የኢትዮ', 'ጽ', 'ያ', '▁ጂ', 'ዲፒ', '▁ምን', '▁ያህል', '▁ነበር', '?']\n",
      "[1459, 0, 464, 2876, 62435, 150, 512, 60, 95]\n"
     ]
    }
   ],
   "source": [
    "sp = spm.SentencePieceProcessor()\n",
    "sp.load('m.model')\n",
    "\n",
    "# encode: text => id\n",
    "print(sp.encode_as_pieces('የኢትዮጽያ ጂዲፒ ምን ያህል ነበር?'))\n",
    "print(sp.encode_as_ids('የኢትዮጽያ ጂዲፒ ምን ያህል ነበር?'))\n",
    "\n",
    "# decode: id => text\n",
    "# print(sp.decode_pieces(['_የኢትዮጽያ', '_ጂዲፒ', '_ምን', '_ያህል', 'ነበር']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁ሃይ', '▁ሰላም', '▁ናችሁ', '?']\n"
     ]
    }
   ],
   "source": [
    "print(sp.encode_as_pieces('ሃይ ሰላም ናችሁ?'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(177) LOG(INFO) Running command: --input=merged_text.txt --model_prefix=am-word --model_type=word  --vocab_size=100000\n",
      "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: merged_text.txt\n",
      "  input_format: \n",
      "  model_prefix: am-word\n",
      "  model_type: WORD\n",
      "  vocab_size: 100000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.9995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  pretokenization_delimiter: \n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "  enable_differential_privacy: 0\n",
      "  differential_privacy_noise_level: 0\n",
      "  differential_privacy_clipping_threshold: 0\n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(351) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(183) LOG(INFO) Loading corpus: merged_text.txt\n",
      "trainer_interface.cc(378) LOG(WARNING) Found too long line (4486 > 4192).\n",
      "trainer_interface.cc(380) LOG(WARNING) Too long lines are skipped in the training.\n",
      "trainer_interface.cc(381) LOG(WARNING) The maximum length can be changed with --max_sentence_length=<size> flag.\n",
      "trainer_interface.cc(389) LOG(INFO) Reserved chars are found. Skipped: ይህን ያውቁ ኖሯል የአለማችን የመጀመሪያዋ መኪና የተሰራችው እንደ ፈረንጆቹ አቆጣጠር በ1885 ሲሆን ሞዴሏም የተሰራው በKarl Benz’s ሲሆን ዲዛይኑ የተወሰደው ደሞ ከፈረስ መሆኑ እኔን ትንሽ አስገርሞኛል!፦ መኪናዋን ሳያት ደሞ አስቆኛልም ምንጭ[Google] New channel Join ▄ ▅ ▆\n",
      "trainer_interface.cc(389) LOG(INFO) Reserved chars are found. Skipped: ይገርማል አንድ አባት የልጁን ህክምና ወጪ ለመሸፈን ኩላሊቱን ሸጦ አድኗት ልጁ ግን ለፍቅረኛዋ ብላ እራሷን አጠፋች ምንጭ[Instagram] ▄ ▅ ▆ ▇\n",
      "trainer_interface.cc(389) LOG(INFO) Reserved chars are found. Skipped: ይገርማል JULIO MACIAS የተባለ ሜክሲኮ ውስጥ የሞኖር የ17 አመት ልጅ ፍቅረኛው በፍቅር አንገቱን ስትነክሰው ሞተ።አስከሬኑ ሲመረመርም ፍቅረኛው ስትነክሰው ወደ አንጎሉ ሚሄደው ደም በመቋረጡ እንደሞተ ተረጋግጧል ምንጭ[Instagram] ▄ ▅ ▆ ▇\n",
      "trainer_interface.cc(389) LOG(INFO) Reserved chars are found. Skipped: ይገርማል ብራዚል ውስጥ ያሉ የግንባታ ሰራተኞች የእግረኛ መንገድ እየሰሩ የሚሰሩበት ቦታ ላይ የቆመ መኪና ነበር። መኪማው እንዲነሳ የመኪናውን ባለቤት ቢፈልጉትም ሊያገኙት ስላልቻሉ ፎቶው ላይ እንደምታዩት አርገውታል ምንጭ[Instagram] ▄ ▅ ▆ ▇\n",
      "trainer_interface.cc(389) LOG(INFO) Reserved chars are found. Skipped: \"ይህን ያውቁ ኖሯል የመጀመሪያው የአሜሪካ ባንክ ዝርፊያ 162,821 የአሜሪካ ዶላር ሲሆን ዘራፊው የዘረፈውን ገንዘብ መልሶ እዛው ባንክ በማስቀመጡ ሊያዝ ችሏል ምንጭ[Instagram] ▄ ▅ ▆ ▇\"\n",
      "trainer_interface.cc(389) LOG(INFO) Reserved chars are found. Skipped: ይህን ያውቁ ኖሯል አንድ ሰውዬ ሙዚየም ውስጥ መነፅሩ ወድቆበት ረስቶ ሲሄድ ሙዚየም ውስጥ የሚገቡ ሰዎች መነፅሩ የጥበብ ስራ መስሏቸው ��ቶ ሲያነሱት ነበር ምንጭ[Instagram] ▄ ▅ ▆ ▇\n",
      "trainer_interface.cc(389) LOG(INFO) Reserved chars are found. Skipped: ይህን ያውቁ ኖሯል በደቡብ ሱዳን 4 ኣይን ያለው አዲስ እንሰሳ ተገኝቷል ምንጭ[Instagram] ▄ ▅ ▆ ▇\n",
      "trainer_interface.cc(389) LOG(INFO) Reserved chars are found. Skipped: ይህን ያውቁ ኖሯል ሴቷ አንበሳ ከወንዱ አንበሳ ጋር ወሲብ ማረግ ፈልጋ ወንዱ እምቢ ካለ ሰቷ የብልቱን ፍሬዎች ትነክሰዋለች ምንጭ[Instagram] ▄ ▅ ▆ ▇\n",
      "trainer_interface.cc(389) LOG(INFO) Reserved chars are found. Skipped: ይገርናል በለንደን የአንዲት ሴት ሶፋ ላይ ቁጭ ብላ tv እያየች ሞተች። ከዚያም ከሞተች 4 አመታት ቡሃላ TVው ክፍት እንደሆነ እሷም ሶፋ ላይ እንደተቀመጠች አፅሟ ተገኘ ምንጭ[Instagram] ▄ ▅ ▆ ▇\n",
      "trainer_interface.cc(389) LOG(INFO) Reserved chars are found. Skipped: ይገርማል አንዱ ተማሪ አምቡላንስ ውስጥ የልብ ምቱ ቆሞ በቃ ሞቷል ከተባለ ቡሃላ ሆስፒታል ውስጥ በድንገት ነቃ። ከዛ ሃኪሞች ከሞት ቡሃላ ህይወት ስሜቱ እንዴት ነው ብለው ሲጠይቁት ሚገርም ነገር ተናገረ። ሞተ በተባለ ሰኣት መንፈሱ ከሞተው ሰውነቱ አጠገብ ተቀምጦ የሆነውን ነገር እንዳየ ተናግሮ አምቡላንስ ውስጥ የተፈጠረውን ነገር በሙሉ አንድም ሳያስቀር ነገራቸው እናም ትክክል ነበር። ምንጭ[Google] ▄ ▅ ▆ ▇\n",
      "trainer_interface.cc(389) LOG(INFO) Reserved chars are found. Skipped: ይህን ያውቁ ኖሯል በህልማቹ ምታዩአቸው ሰዎች በሙሉ በእውነተኛ ህይወታቹ ያያቹሃቸው ሰዎች ናቸው ምክንያቱም ጭንቅላታችን አዲስ ፊት መፍጠ�� አይችልም ምንጭ[Instagram] ▄ ▅ ▆ ▇\n",
      "trainer_interface.cc(407) LOG(INFO) Loaded all 518282 sentences\n",
      "trainer_interface.cc(414) LOG(INFO) Skipped 2312 too long sentences.\n",
      "trainer_interface.cc(423) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(423) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(423) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(428) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(537) LOG(INFO) all chars count=73348508\n",
      "trainer_interface.cc(548) LOG(INFO) Done: 99.9511% characters are covered.\n",
      "trainer_interface.cc(558) LOG(INFO) Alphabet size=330\n",
      "trainer_interface.cc(559) LOG(INFO) Final character coverage=0.999511\n",
      "trainer_interface.cc(591) LOG(INFO) Done! preprocessed 517901 sentences.\n",
      "trainer_interface.cc(686) LOG(INFO) Saving model: am-word.model\n",
      "trainer_interface.cc(698) LOG(INFO) Saving vocabs: am-word.vocab\n"
     ]
    }
   ],
   "source": [
    "# train sentencepiece model from `merged_text.txt` and makes `m.model` and `m.vocab`\n",
    "# `m.vocab` is just a reference. not used in the segmentation.\n",
    "# spm.SentencePieceTrainer.train('--input=merged_text.txt --model_prefix=am-word --model_type=word, --vocab_size=100000')\n",
    "spm.SentencePieceTrainer.train('--input=merged_text.txt --model_prefix=am-word --model_type=word  --vocab_size=100000')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁የኢትዮጽያ▁ጂዲፒ', '▁ምን', '▁ያህል', '▁ነበር?']\n",
      "[0, 125, 427, 6011]\n"
     ]
    }
   ],
   "source": [
    "sp = spm.SentencePieceProcessor()\n",
    "sp.load('am-word.model')\n",
    "\n",
    "print(sp.encode_as_pieces('የኢትዮጽያ  ጂዲፒ ምን ያህል ነበር?'))\n",
    "print(sp.encode_as_ids('የኢትዮጽያ ጂዲፒ ምን ያህል ነበር?'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁በአዲስ', '▁አበባ', '▁የአሜሪካ', '▁ኤምባሲ']\n",
      "[201, 45, 515, 2032]\n"
     ]
    }
   ],
   "source": [
    "sp = spm.SentencePieceProcessor()\n",
    "sp.load('am-word.model')\n",
    "\n",
    "print(sp.encode_as_pieces('በአዲስ አበባ የአሜሪካ ኤምባሲ'))\n",
    "print(sp.encode_as_ids('በአዲስ አበባ የአሜሪካ ኤምባሲ'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁የፒዛ', '▁ምግብ', '▁ቤት', '▁ለመክፈት', '▁የሚጠቅሙ', '▁ምክሮች']\n",
      "[47914, 1024, 33, 7716, 29922, 26700]\n",
      "ፒዛ ምግብ ቤት ለመክፈት የሚጠቅሙ ምክሮች\n"
     ]
    }
   ],
   "source": [
    "sp = spm.SentencePieceProcessor()\n",
    "sp.load('am-word.model')\n",
    "\n",
    "print(sp.encode_as_pieces('የፒዛ ምግብ ቤት ለመክፈት የሚጠቅሙ ምክሮች'))\n",
    "print(sp.encode_as_ids('ፒዛ ምግብ ቤት ለመክፈት የሚጠቅሙ ምክሮች'))\n",
    "print(sp.decode_ids([47914, 1024, 33, 7716, 29922, 26700]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
